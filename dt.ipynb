{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e05d9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baed1aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('p.values.xlsx', sheet_name = 'Totaldata (wrapper-filter) (3)', header = None).transpose()\n",
    "labels = pd.read_excel('p.values.xlsx',sheet_name = 'Label', header = None).transpose()\n",
    "\n",
    "#data = data.dropna()\n",
    "#data = data.drop_duplicates()\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d3e943",
   "metadata": {},
   "outputs": [],
   "source": [
    "standardizer = StandardScaler()\n",
    " \n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    " \n",
    "\n",
    "pipeline = make_pipeline(standardizer, dt)\n",
    " \n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756d7562",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(dt,data, labels,cv=kf,  scoring=\"precision\",n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f60ebc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(dt,data, labels,cv=kf,  scoring=\"precision\",n_jobs=-1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29c7e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(dt,data, labels,cv=kf, scoring=\"recall\",n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5233ea5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(dt,data, labels,cv=kf, scoring=\"recall\",n_jobs=-1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827054bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(dt,data, labels,cv=kf, scoring=\"f1\",n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fb1170",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(dt,data, labels,cv=kf, scoring=\"f1\",n_jobs=-1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f64936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and test split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=1)\n",
    " \n",
    "# Predict values for training target vector\n",
    "\n",
    "y_hat = dt.fit(X_train, y_train).predict(X_test)\n",
    " \n",
    "# Calculate accuracy\n",
    "\n",
    "accuracy_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0302a354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and test sets\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "\n",
    "data, labels, test_size=0.3, random_state=1)\n",
    " \n",
    "# Train model\n",
    "\n",
    "dt.fit(features_train, target_train)\n",
    " \n",
    "# Get predicted probabilities\n",
    "\n",
    "target_probabilities = dt.predict_proba(features_test)[:,1]\n",
    " \n",
    "# Create true and false positive rates\n",
    "\n",
    "false_positive_rate, true_positive_rate, threshold = roc_curve(target_test,\n",
    "\n",
    "target_probabilities)\n",
    " \n",
    "# Plot ROC curve\n",
    "\n",
    "plt.title(\"Receiver Operating Characteristic\")\n",
    "\n",
    "plt.plot(false_positive_rate, true_positive_rate)\n",
    "\n",
    "plt.plot([0, 1], ls=\"--\")\n",
    "\n",
    "plt.plot([0, 0], [1, 0] , c=\".7\"), plt.plot([1, 1] , c=\".7\")\n",
    "\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# predict probabilities\n",
    "target_probabilities = dt.predict_proba(features_test)[:,1]\n",
    "\n",
    "# predict class values\n",
    "target_predicted = dt.predict(features_test)\n",
    "\n",
    "# plot the precision-recall curves\n",
    "lr_precision, lr_recall, _ = precision_recall_curve(target_test,target_probabilities)\n",
    "data = len(target_test[target_test==1]) / len(target_test)\n",
    "pyplot.plot([0, 1], [data, data], linestyle='--', label='No')\n",
    "pyplot.plot(lr_recall, lr_precision, marker='.', label='Stack Model')\n",
    "# axis labels\n",
    "pyplot.xlabel('Recall')\n",
    "pyplot.ylabel('Precision')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()\n",
    "\n",
    "average_precision = average_precision_score(target_test,target_probabilities)\n",
    "print(average_precision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0b7020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted probabilities\n",
    "dt.predict_proba(features_test)[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd84604",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate area under curve\n",
    "roc_auc_score(target_test, target_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce3017a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9d1938",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
